{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_batch_norm_1d(x,gama,beta):\n",
    "    eps=1e-5\n",
    "    x_mean=torch.mean(x,dim=0,keepdim=True)\n",
    "    x_var=torch.mean((x-x_mean)**2,dim=0,keepdim=True)\n",
    "    x_hat=(x-x_mean)/torch.sqrt(x_var+eps)\n",
    "    return gama.view_as(x_mean)*x_hat+beta.view_as(x_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before bn:\n",
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.],\n",
      "        [12., 13., 14.]])\n",
      "after bn:\n",
      "tensor([[-1.4142, -1.4142, -1.4142],\n",
      "        [-0.7071, -0.7071, -0.7071],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.7071,  0.7071,  0.7071],\n",
      "        [ 1.4142,  1.4142,  1.4142]])\n"
     ]
    }
   ],
   "source": [
    "x= torch.arange(15).view(5,3)\n",
    "x=x.type(torch.FloatTensor)\n",
    "gama=torch.ones(x.shape[1])\n",
    "beta=torch.zeros(x.shape[1])\n",
    "print('before bn:')\n",
    "print(x)\n",
    "y=simple_batch_norm_1d(x,gama,beta)\n",
    "print('after bn:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm_1d(x,gamma,beta,is_traing,moving_mean,moving_var,moving_momentum=0.1):\n",
    "    eps=1e-5\n",
    "    x_mean=torch.mean(x,dim=0,keepdim=True)\n",
    "    x_var=torch.mean((x-x_mean)**2,dim=0,keepdim=True)\n",
    "    if is_traing:\n",
    "        x_hat=(x-x_mean)/torch.sqrt(x_var+eps)\n",
    "        moving_mean[:]=moving_momentum*moving_mean+(1.-moving_momentum)*x_mean\n",
    "        moving_var[:]=moving_momentum*moving_var+(1.-moving_momentum)*x_var\n",
    "    else:\n",
    "        x_hat=(x-moving_mean)/torch.sqrt(moving_var+eps)\n",
    "    return gamma.view_as(x_mean)*x_hat+beta.view_as(x_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import mnist # 导入 pytorch 内置的 mnist 数据\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用内置函数下载 mnist 数据集\n",
    "train_set = mnist.MNIST('./data', train=True)\n",
    "test_set = mnist.MNIST('./data', train=False)\n",
    "\n",
    "def data_tf(x):\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x - 0.5) / 0.5 # 数据预处理，标准化\n",
    "    x = x.reshape((-1,)) # 拉平\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "train_set = mnist.MNIST('./data', train=True, transform=data_tf, download=True) # 重新载入数据集，申明定义的数据变换\n",
    "test_set = mnist.MNIST('./data', train=False, transform=data_tf, download=True)\n",
    "train_data = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class multi_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(multi_network,self).__init__()\n",
    "        self.layer1=nn.Linear(784,100)\n",
    "        self.relu=nn.ReLU(True)\n",
    "        self.layer2=nn.Linear(100,10)\n",
    "        \n",
    "        self.gamma=nn.Parameter(torch.randn(100))\n",
    "        self.beta=nn.Parameter(torch.randn(100))\n",
    "        \n",
    "        self.moving_mean=Variable(torch.zeros(100))\n",
    "        self.moving_var=Variable(torch.zeros(100))\n",
    "    def forward(self,x,is_train=True):\n",
    "        x=self.layer1(x)\n",
    "        x=batch_norm_1d(x,self.gamma,self.beta,is_train,self.moving_mean,self.moving_var)\n",
    "        x=self.relu(x)\n",
    "        x=self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_network(\n",
      "  (layer1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (layer2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=multi_network()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(net.parameters(),lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEMP\\Desktop\\Pytorch\\utils.py:58: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  im = Variable(im, volatile=True)\n",
      "C:\\Users\\TEMP\\Desktop\\Pytorch\\utils.py:59: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  label = Variable(label, volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 0.307045, Train Acc: 0.914729, Valid Loss: 0.181659, Valid Acc: 0.946499, Time 00:00:08\n",
      "Epoch 1. Train Loss: 0.166932, Train Acc: 0.952225, Valid Loss: 0.137236, Valid Acc: 0.958366, Time 00:00:09\n",
      "Epoch 2. Train Loss: 0.129827, Train Acc: 0.962836, Valid Loss: 0.116029, Valid Acc: 0.965981, Time 00:00:08\n",
      "Epoch 3. Train Loss: 0.106928, Train Acc: 0.969650, Valid Loss: 0.110975, Valid Acc: 0.967959, Time 00:00:09\n",
      "Epoch 4. Train Loss: 0.092049, Train Acc: 0.973847, Valid Loss: 0.096674, Valid Acc: 0.970728, Time 00:00:09\n",
      "Epoch 5. Train Loss: 0.081043, Train Acc: 0.976396, Valid Loss: 0.097490, Valid Acc: 0.970629, Time 00:00:10\n",
      "Epoch 6. Train Loss: 0.072950, Train Acc: 0.978628, Valid Loss: 0.091845, Valid Acc: 0.972112, Time 00:00:09\n",
      "Epoch 7. Train Loss: 0.066913, Train Acc: 0.979944, Valid Loss: 0.092770, Valid Acc: 0.970827, Time 00:00:09\n",
      "Epoch 8. Train Loss: 0.059466, Train Acc: 0.982060, Valid Loss: 0.091550, Valid Acc: 0.971519, Time 00:00:09\n",
      "Epoch 9. Train Loss: 0.055991, Train Acc: 0.982826, Valid Loss: 0.086576, Valid Acc: 0.974189, Time 00:00:09\n"
     ]
    }
   ],
   "source": [
    "train(net, train_data, test_data, 10, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.9455,  1.7531, -1.0747, -1.0521,  1.1635,  0.7730,  0.3855, -1.4986,\n",
      "        -1.3545, -0.6360], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 打出 moving_mean 的前 10 项\n",
    "print(net.moving_mean[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEMP\\Desktop\\Pytorch\\utils.py:58: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  im = Variable(im, volatile=True)\n",
      "C:\\Users\\TEMP\\Desktop\\Pytorch\\utils.py:59: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  label = Variable(label, volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 0.402252, Train Acc: 0.873567, Valid Loss: 0.220926, Valid Acc: 0.935918, Time 00:00:07\n",
      "Epoch 1. Train Loss: 0.184110, Train Acc: 0.944313, Valid Loss: 0.147016, Valid Acc: 0.957377, Time 00:00:09\n",
      "Epoch 2. Train Loss: 0.136039, Train Acc: 0.959322, Valid Loss: 0.147227, Valid Acc: 0.955696, Time 00:00:08\n",
      "Epoch 3. Train Loss: 0.109659, Train Acc: 0.966801, Valid Loss: 0.138487, Valid Acc: 0.955498, Time 00:00:09\n",
      "Epoch 4. Train Loss: 0.094737, Train Acc: 0.970999, Valid Loss: 0.111056, Valid Acc: 0.965981, Time 00:00:09\n",
      "Epoch 5. Train Loss: 0.083283, Train Acc: 0.974530, Valid Loss: 0.110512, Valid Acc: 0.965684, Time 00:00:09\n",
      "Epoch 6. Train Loss: 0.073668, Train Acc: 0.977412, Valid Loss: 0.093237, Valid Acc: 0.972508, Time 00:00:08\n",
      "Epoch 7. Train Loss: 0.066807, Train Acc: 0.978911, Valid Loss: 0.138552, Valid Acc: 0.958663, Time 00:00:08\n",
      "Epoch 8. Train Loss: 0.061216, Train Acc: 0.980877, Valid Loss: 0.122029, Valid Acc: 0.961926, Time 00:00:08\n",
      "Epoch 9. Train Loss: 0.054883, Train Acc: 0.983042, Valid Loss: 0.082639, Valid Acc: 0.974881, Time 00:00:08\n"
     ]
    }
   ],
   "source": [
    "no_bn_net = nn.Sequential(\n",
    "    nn.Linear(784, 100),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(100, 10)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(no_bn_net.parameters(), 1e-1) # 使用随机梯度下降，学习率 0.1\n",
    "train(no_bn_net, train_data, test_data, 10, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_tf(x):\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x - 0.5) / 0.5 # 数据预处理，标准化\n",
    "    x = torch.from_numpy(x)\n",
    "    x = x.unsqueeze(0)\n",
    "    return x\n",
    "\n",
    "train_set = mnist.MNIST('./data', train=True, transform=data_tf, download=True) # 重新载入数据集，申明定义的数据变换\n",
    "test_set = mnist.MNIST('./data', train=False, transform=data_tf, download=True)\n",
    "train_data = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class conv_bn_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_bn_net,self).__init__()\n",
    "        self.stage1=nn.Sequential(\n",
    "            nn.Conv2d(1,6,3,padding=1),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(6,16,5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.classfy=nn.Linear(400,10)\n",
    "    def forward(self,x):\n",
    "        x=self.stage1(x)\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        x=self.classfy(x)\n",
    "        return x\n",
    "    \n",
    "net=conv_bn_net()\n",
    "optimizer=torch.optim.SGD(net.parameters(),lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEMP\\Desktop\\Pytorch\\utils.py:58: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  im = Variable(im, volatile=True)\n",
      "C:\\Users\\TEMP\\Desktop\\Pytorch\\utils.py:59: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  label = Variable(label, volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 0.158638, Train Acc: 0.953242, Valid Loss: 0.064446, Valid Acc: 0.979628, Time 00:00:53\n",
      "Epoch 1. Train Loss: 0.065400, Train Acc: 0.979994, Valid Loss: 0.059181, Valid Acc: 0.980222, Time 00:00:56\n",
      "Epoch 2. Train Loss: 0.052123, Train Acc: 0.984025, Valid Loss: 0.050308, Valid Acc: 0.983386, Time 00:00:58\n",
      "Epoch 3. Train Loss: 0.044278, Train Acc: 0.986291, Valid Loss: 0.040967, Valid Acc: 0.986056, Time 00:00:56\n",
      "Epoch 4. Train Loss: 0.039090, Train Acc: 0.987940, Valid Loss: 0.038483, Valid Acc: 0.987441, Time 00:00:57\n"
     ]
    }
   ],
   "source": [
    "train(net, train_data, test_data, 5, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 不使用批标准化\n",
    "class conv_no_bn_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_no_bn_net, self).__init__()\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.classfy = nn.Linear(400, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.classfy(x)\n",
    "        return x\n",
    "\n",
    "net = conv_no_bn_net()\n",
    "optimizer = torch.optim.SGD(net.parameters(), 1e-1) # 使用随机梯度下降，学习率 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TEMP\\Desktop\\Pytorch\\utils.py:58: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  im = Variable(im, volatile=True)\n",
      "C:\\Users\\TEMP\\Desktop\\Pytorch\\utils.py:59: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  label = Variable(label, volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 0.212905, Train Acc: 0.934768, Valid Loss: 0.109351, Valid Acc: 0.963509, Time 00:00:37\n",
      "Epoch 1. Train Loss: 0.071837, Train Acc: 0.977978, Valid Loss: 0.047891, Valid Acc: 0.984078, Time 00:00:39\n",
      "Epoch 2. Train Loss: 0.054570, Train Acc: 0.982959, Valid Loss: 0.045030, Valid Acc: 0.985562, Time 00:00:43\n",
      "Epoch 3. Train Loss: 0.044837, Train Acc: 0.986057, Valid Loss: 0.042893, Valid Acc: 0.986748, Time 00:00:38\n",
      "Epoch 4. Train Loss: 0.039101, Train Acc: 0.987807, Valid Loss: 0.038874, Valid Acc: 0.986353, Time 00:00:37\n"
     ]
    }
   ],
   "source": [
    "train(net, train_data, test_data, 5, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
