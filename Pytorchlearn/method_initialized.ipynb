{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net1=nn.Sequential(\n",
    "    nn.Linear(30,40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40,50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1=net1[0].weight\n",
    "b1=net1[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0706, -0.0300,  0.0809,  ...,  0.1337, -0.1517, -0.1413],\n",
      "        [ 0.1603, -0.1201, -0.0126,  ..., -0.0802, -0.1273, -0.1170],\n",
      "        [ 0.1785,  0.0826,  0.1420,  ...,  0.0677,  0.1163, -0.1700],\n",
      "        ...,\n",
      "        [ 0.0409,  0.1592,  0.1117,  ...,  0.0018,  0.0550, -0.0920],\n",
      "        [ 0.1289,  0.0320,  0.1599,  ...,  0.1045, -0.0394,  0.0304],\n",
      "        [ 0.0380, -0.1638,  0.1335,  ...,  0.0956,  0.0536,  0.1322]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net1[0].weight.data=torch.from_numpy(np.random.uniform(3,5,size=(40,30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[3.8753, 3.1928, 3.9959,  ..., 4.3677, 4.7646, 3.4888],\n",
      "        [3.8110, 3.7116, 3.3725,  ..., 3.3414, 3.9001, 3.4464],\n",
      "        [3.4373, 4.0609, 4.6713,  ..., 4.3985, 4.8385, 4.7497],\n",
      "        ...,\n",
      "        [4.2926, 3.7396, 4.9737,  ..., 3.4710, 4.7653, 4.2036],\n",
      "        [4.5235, 4.8773, 4.8815,  ..., 4.6595, 3.7931, 4.4269],\n",
      "        [4.8298, 4.6019, 4.3595,  ..., 3.8497, 3.5075, 4.7963]],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(net1[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sim_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sim_net,self).__init__()\n",
    "        self.l1= nn.Sequential(\n",
    "            nn.Linear(30,40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l1[0].weight.data=torch.randn(40,30)\n",
    "        self.l2= nn.Sequential(\n",
    "            nn.Linear(40,50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l3= nn.Sequential(\n",
    "            nn.Linear(50,10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.l1(x)\n",
    "        x=self.l2(x)\n",
    "        x=self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2=sim_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=30, out_features=40, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=40, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 访问 children\n",
    "for i in net2.children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_net(\n",
      "  (l1): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=40, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l2): Sequential(\n",
      "    (0): Linear(in_features=40, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l3): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=30, out_features=40, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Linear(in_features=30, out_features=40, bias=True)\n",
      "ReLU()\n",
      "Sequential(\n",
      "  (0): Linear(in_features=40, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Linear(in_features=40, out_features=50, bias=True)\n",
      "ReLU()\n",
      "Sequential(\n",
      "  (0): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Linear(in_features=50, out_features=10, bias=True)\n",
      "ReLU()\n"
     ]
    }
   ],
   "source": [
    "# 访问 modules\n",
    "for i in net2.modules():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in net2.modules():\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        param_shape = layer.weight.shape\n",
    "        layer.weight.data = torch.from_numpy(np.random.normal(0, 0.5, size=param_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[3.8753, 3.1928, 3.9959,  ..., 4.3677, 4.7646, 3.4888],\n",
      "        [3.8110, 3.7116, 3.3725,  ..., 3.3414, 3.9001, 3.4464],\n",
      "        [3.4373, 4.0609, 4.6713,  ..., 4.3985, 4.8385, 4.7497],\n",
      "        ...,\n",
      "        [4.2926, 3.7396, 4.9737,  ..., 3.4710, 4.7653, 4.2036],\n",
      "        [4.5235, 4.8773, 4.8815,  ..., 4.6595, 3.7931, 4.4269],\n",
      "        [4.8298, 4.6019, 4.3595,  ..., 3.8497, 3.5075, 4.7963]],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(net1[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1370,  0.1829, -0.1048,  ...,  0.0640,  0.2180,  0.1076],\n",
       "        [-0.2274, -0.0716, -0.0438,  ...,  0.0617, -0.1926, -0.2118],\n",
       "        [-0.0875,  0.1350, -0.2081,  ..., -0.0903, -0.1176,  0.1613],\n",
       "        ...,\n",
       "        [ 0.1258, -0.1652, -0.0627,  ..., -0.1223,  0.2487, -0.2729],\n",
       "        [-0.0035,  0.0480,  0.1564,  ...,  0.1210, -0.0176, -0.2005],\n",
       "        [-0.2840, -0.1037,  0.1223,  ...,  0.2567, -0.2167,  0.0614]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.xavier_uniform(net1[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1370,  0.1829, -0.1048,  ...,  0.0640,  0.2180,  0.1076],\n",
      "        [-0.2274, -0.0716, -0.0438,  ...,  0.0617, -0.1926, -0.2118],\n",
      "        [-0.0875,  0.1350, -0.2081,  ..., -0.0903, -0.1176,  0.1613],\n",
      "        ...,\n",
      "        [ 0.1258, -0.1652, -0.0627,  ..., -0.1223,  0.2487, -0.2729],\n",
      "        [-0.0035,  0.0480,  0.1564,  ...,  0.1210, -0.0176, -0.2005],\n",
      "        [-0.2840, -0.1037,  0.1223,  ...,  0.2567, -0.2167,  0.0614]],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(net1[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
